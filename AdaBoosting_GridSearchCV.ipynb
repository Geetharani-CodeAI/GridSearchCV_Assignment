{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d012f52-b18a-41c7-b9ef-e3113bceb31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\hxtreme\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\hxtreme\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\hxtreme\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad76a0b-bc38-41e0-8902-4c52b508b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "021e61f4-b30e-496a-913f-dd3fd02bbcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.read_csv(\"50_Startups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af34310-18d4-4c2f-a8a4-6e754695b7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>New York</td>\n",
       "      <td>156991.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>California</td>\n",
       "      <td>156122.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>Florida</td>\n",
       "      <td>155752.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>152211.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>California</td>\n",
       "      <td>149759.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>Florida</td>\n",
       "      <td>146121.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>California</td>\n",
       "      <td>144259.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>Florida</td>\n",
       "      <td>141585.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>California</td>\n",
       "      <td>134307.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>Florida</td>\n",
       "      <td>132602.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>New York</td>\n",
       "      <td>129917.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>California</td>\n",
       "      <td>126992.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>New York</td>\n",
       "      <td>125370.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>Florida</td>\n",
       "      <td>124266.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>New York</td>\n",
       "      <td>122776.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>California</td>\n",
       "      <td>118474.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>111313.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>Florida</td>\n",
       "      <td>110352.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>Florida</td>\n",
       "      <td>108733.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>New York</td>\n",
       "      <td>108552.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>California</td>\n",
       "      <td>107404.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>Florida</td>\n",
       "      <td>105733.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>New York</td>\n",
       "      <td>105008.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>Florida</td>\n",
       "      <td>103282.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>New York</td>\n",
       "      <td>101004.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>Florida</td>\n",
       "      <td>99937.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>New York</td>\n",
       "      <td>97483.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>California</td>\n",
       "      <td>97427.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>Florida</td>\n",
       "      <td>96778.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>California</td>\n",
       "      <td>96712.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>New York</td>\n",
       "      <td>96479.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>Florida</td>\n",
       "      <td>90708.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>California</td>\n",
       "      <td>89949.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>81229.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>California</td>\n",
       "      <td>81005.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>California</td>\n",
       "      <td>78239.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>Florida</td>\n",
       "      <td>77798.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>California</td>\n",
       "      <td>71498.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>New York</td>\n",
       "      <td>69758.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>California</td>\n",
       "      <td>65200.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>New York</td>\n",
       "      <td>64926.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>Florida</td>\n",
       "      <td>49490.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>California</td>\n",
       "      <td>42559.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>New York</td>\n",
       "      <td>35673.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>California</td>\n",
       "      <td>14681.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0   165349.20       136897.80        471784.10    New York  192261.83\n",
       "1   162597.70       151377.59        443898.53  California  191792.06\n",
       "2   153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3   144372.41       118671.85        383199.62    New York  182901.99\n",
       "4   142107.34        91391.77        366168.42     Florida  166187.94\n",
       "5   131876.90        99814.71        362861.36    New York  156991.12\n",
       "6   134615.46       147198.87        127716.82  California  156122.51\n",
       "7   130298.13       145530.06        323876.68     Florida  155752.60\n",
       "8   120542.52       148718.95        311613.29    New York  152211.77\n",
       "9   123334.88       108679.17        304981.62  California  149759.96\n",
       "10  101913.08       110594.11        229160.95     Florida  146121.95\n",
       "11  100671.96        91790.61        249744.55  California  144259.40\n",
       "12   93863.75       127320.38        249839.44     Florida  141585.52\n",
       "13   91992.39       135495.07        252664.93  California  134307.35\n",
       "14  119943.24       156547.42        256512.92     Florida  132602.65\n",
       "15  114523.61       122616.84        261776.23    New York  129917.04\n",
       "16   78013.11       121597.55        264346.06  California  126992.93\n",
       "17   94657.16       145077.58        282574.31    New York  125370.37\n",
       "18   91749.16       114175.79        294919.57     Florida  124266.90\n",
       "19   86419.70       153514.11             0.00    New York  122776.86\n",
       "20   76253.86       113867.30        298664.47  California  118474.03\n",
       "21   78389.47       153773.43        299737.29    New York  111313.02\n",
       "22   73994.56       122782.75        303319.26     Florida  110352.25\n",
       "23   67532.53       105751.03        304768.73     Florida  108733.99\n",
       "24   77044.01        99281.34        140574.81    New York  108552.04\n",
       "25   64664.71       139553.16        137962.62  California  107404.34\n",
       "26   75328.87       144135.98        134050.07     Florida  105733.54\n",
       "27   72107.60       127864.55        353183.81    New York  105008.31\n",
       "28   66051.52       182645.56        118148.20     Florida  103282.38\n",
       "29   65605.48       153032.06        107138.38    New York  101004.64\n",
       "30   61994.48       115641.28         91131.24     Florida   99937.59\n",
       "31   61136.38       152701.92         88218.23    New York   97483.56\n",
       "32   63408.86       129219.61         46085.25  California   97427.84\n",
       "33   55493.95       103057.49        214634.81     Florida   96778.92\n",
       "34   46426.07       157693.92        210797.67  California   96712.80\n",
       "35   46014.02        85047.44        205517.64    New York   96479.51\n",
       "36   28663.76       127056.21        201126.82     Florida   90708.19\n",
       "37   44069.95        51283.14        197029.42  California   89949.14\n",
       "38   20229.59        65947.93        185265.10    New York   81229.06\n",
       "39   38558.51        82982.09        174999.30  California   81005.76\n",
       "40   28754.33       118546.05        172795.67  California   78239.91\n",
       "41   27892.92        84710.77        164470.71     Florida   77798.83\n",
       "42   23640.93        96189.63        148001.11  California   71498.49\n",
       "43   15505.73       127382.30         35534.17    New York   69758.98\n",
       "44   22177.74       154806.14         28334.72  California   65200.33\n",
       "45    1000.23       124153.04          1903.93    New York   64926.08\n",
       "46    1315.46       115816.21        297114.46     Florida   49490.75\n",
       "47       0.00       135426.92             0.00  California   42559.73\n",
       "48     542.05        51743.15             0.00    New York   35673.41\n",
       "49       0.00       116983.80         45173.06  California   14681.40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c07a3d-a5a3-4b99-b6d5-b1ddea2d8297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "      <th>State_Florida</th>\n",
       "      <th>State_New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>192261.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>191792.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>191050.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>182901.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>166187.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>156991.12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>156122.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>155752.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>152211.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>149759.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>146121.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>144259.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>141585.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>134307.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>132602.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>129917.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>126992.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>125370.37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>124266.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>122776.86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>118474.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>111313.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>110352.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>108733.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>108552.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>107404.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>105733.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>105008.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>103282.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>101004.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>99937.59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>97483.56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>97427.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>96778.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>96712.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>96479.51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>90708.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>89949.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>81229.06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>81005.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>78239.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>77798.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>71498.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>69758.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>65200.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>64926.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>49490.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42559.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35673.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>14681.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend     Profit  State_Florida  \\\n",
       "0   165349.20       136897.80        471784.10  192261.83              0   \n",
       "1   162597.70       151377.59        443898.53  191792.06              0   \n",
       "2   153441.51       101145.55        407934.54  191050.39              1   \n",
       "3   144372.41       118671.85        383199.62  182901.99              0   \n",
       "4   142107.34        91391.77        366168.42  166187.94              1   \n",
       "5   131876.90        99814.71        362861.36  156991.12              0   \n",
       "6   134615.46       147198.87        127716.82  156122.51              0   \n",
       "7   130298.13       145530.06        323876.68  155752.60              1   \n",
       "8   120542.52       148718.95        311613.29  152211.77              0   \n",
       "9   123334.88       108679.17        304981.62  149759.96              0   \n",
       "10  101913.08       110594.11        229160.95  146121.95              1   \n",
       "11  100671.96        91790.61        249744.55  144259.40              0   \n",
       "12   93863.75       127320.38        249839.44  141585.52              1   \n",
       "13   91992.39       135495.07        252664.93  134307.35              0   \n",
       "14  119943.24       156547.42        256512.92  132602.65              1   \n",
       "15  114523.61       122616.84        261776.23  129917.04              0   \n",
       "16   78013.11       121597.55        264346.06  126992.93              0   \n",
       "17   94657.16       145077.58        282574.31  125370.37              0   \n",
       "18   91749.16       114175.79        294919.57  124266.90              1   \n",
       "19   86419.70       153514.11             0.00  122776.86              0   \n",
       "20   76253.86       113867.30        298664.47  118474.03              0   \n",
       "21   78389.47       153773.43        299737.29  111313.02              0   \n",
       "22   73994.56       122782.75        303319.26  110352.25              1   \n",
       "23   67532.53       105751.03        304768.73  108733.99              1   \n",
       "24   77044.01        99281.34        140574.81  108552.04              0   \n",
       "25   64664.71       139553.16        137962.62  107404.34              0   \n",
       "26   75328.87       144135.98        134050.07  105733.54              1   \n",
       "27   72107.60       127864.55        353183.81  105008.31              0   \n",
       "28   66051.52       182645.56        118148.20  103282.38              1   \n",
       "29   65605.48       153032.06        107138.38  101004.64              0   \n",
       "30   61994.48       115641.28         91131.24   99937.59              1   \n",
       "31   61136.38       152701.92         88218.23   97483.56              0   \n",
       "32   63408.86       129219.61         46085.25   97427.84              0   \n",
       "33   55493.95       103057.49        214634.81   96778.92              1   \n",
       "34   46426.07       157693.92        210797.67   96712.80              0   \n",
       "35   46014.02        85047.44        205517.64   96479.51              0   \n",
       "36   28663.76       127056.21        201126.82   90708.19              1   \n",
       "37   44069.95        51283.14        197029.42   89949.14              0   \n",
       "38   20229.59        65947.93        185265.10   81229.06              0   \n",
       "39   38558.51        82982.09        174999.30   81005.76              0   \n",
       "40   28754.33       118546.05        172795.67   78239.91              0   \n",
       "41   27892.92        84710.77        164470.71   77798.83              1   \n",
       "42   23640.93        96189.63        148001.11   71498.49              0   \n",
       "43   15505.73       127382.30         35534.17   69758.98              0   \n",
       "44   22177.74       154806.14         28334.72   65200.33              0   \n",
       "45    1000.23       124153.04          1903.93   64926.08              0   \n",
       "46    1315.46       115816.21        297114.46   49490.75              1   \n",
       "47       0.00       135426.92             0.00   42559.73              0   \n",
       "48     542.05        51743.15             0.00   35673.41              0   \n",
       "49       0.00       116983.80         45173.06   14681.40              0   \n",
       "\n",
       "    State_New York  \n",
       "0                1  \n",
       "1                0  \n",
       "2                0  \n",
       "3                1  \n",
       "4                0  \n",
       "5                1  \n",
       "6                0  \n",
       "7                0  \n",
       "8                1  \n",
       "9                0  \n",
       "10               0  \n",
       "11               0  \n",
       "12               0  \n",
       "13               0  \n",
       "14               0  \n",
       "15               1  \n",
       "16               0  \n",
       "17               1  \n",
       "18               0  \n",
       "19               1  \n",
       "20               0  \n",
       "21               1  \n",
       "22               0  \n",
       "23               0  \n",
       "24               1  \n",
       "25               0  \n",
       "26               0  \n",
       "27               1  \n",
       "28               0  \n",
       "29               1  \n",
       "30               0  \n",
       "31               1  \n",
       "32               0  \n",
       "33               0  \n",
       "34               0  \n",
       "35               1  \n",
       "36               0  \n",
       "37               0  \n",
       "38               1  \n",
       "39               0  \n",
       "40               0  \n",
       "41               0  \n",
       "42               0  \n",
       "43               1  \n",
       "44               0  \n",
       "45               1  \n",
       "46               0  \n",
       "47               0  \n",
       "48               1  \n",
       "49               0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.get_dummies(dataset,dtype=int,drop_first=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dbc8ff4-ff62-49b6-9f67-256ba117efcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['R&D Spend', 'Administration', 'Marketing Spend', 'Profit',\n",
       "       'State_Florida', 'State_New York'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d155c7-3bda-41fe-b751-18409aaad10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State_Florida</th>\n",
       "      <th>State_New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend  State_Florida  State_New York\n",
       "0   165349.20       136897.80        471784.10              0               1\n",
       "1   162597.70       151377.59        443898.53              0               0\n",
       "2   153441.51       101145.55        407934.54              1               0\n",
       "3   144372.41       118671.85        383199.62              0               1\n",
       "4   142107.34        91391.77        366168.42              1               0\n",
       "5   131876.90        99814.71        362861.36              0               1\n",
       "6   134615.46       147198.87        127716.82              0               0\n",
       "7   130298.13       145530.06        323876.68              1               0\n",
       "8   120542.52       148718.95        311613.29              0               1\n",
       "9   123334.88       108679.17        304981.62              0               0\n",
       "10  101913.08       110594.11        229160.95              1               0\n",
       "11  100671.96        91790.61        249744.55              0               0\n",
       "12   93863.75       127320.38        249839.44              1               0\n",
       "13   91992.39       135495.07        252664.93              0               0\n",
       "14  119943.24       156547.42        256512.92              1               0\n",
       "15  114523.61       122616.84        261776.23              0               1\n",
       "16   78013.11       121597.55        264346.06              0               0\n",
       "17   94657.16       145077.58        282574.31              0               1\n",
       "18   91749.16       114175.79        294919.57              1               0\n",
       "19   86419.70       153514.11             0.00              0               1\n",
       "20   76253.86       113867.30        298664.47              0               0\n",
       "21   78389.47       153773.43        299737.29              0               1\n",
       "22   73994.56       122782.75        303319.26              1               0\n",
       "23   67532.53       105751.03        304768.73              1               0\n",
       "24   77044.01        99281.34        140574.81              0               1\n",
       "25   64664.71       139553.16        137962.62              0               0\n",
       "26   75328.87       144135.98        134050.07              1               0\n",
       "27   72107.60       127864.55        353183.81              0               1\n",
       "28   66051.52       182645.56        118148.20              1               0\n",
       "29   65605.48       153032.06        107138.38              0               1\n",
       "30   61994.48       115641.28         91131.24              1               0\n",
       "31   61136.38       152701.92         88218.23              0               1\n",
       "32   63408.86       129219.61         46085.25              0               0\n",
       "33   55493.95       103057.49        214634.81              1               0\n",
       "34   46426.07       157693.92        210797.67              0               0\n",
       "35   46014.02        85047.44        205517.64              0               1\n",
       "36   28663.76       127056.21        201126.82              1               0\n",
       "37   44069.95        51283.14        197029.42              0               0\n",
       "38   20229.59        65947.93        185265.10              0               1\n",
       "39   38558.51        82982.09        174999.30              0               0\n",
       "40   28754.33       118546.05        172795.67              0               0\n",
       "41   27892.92        84710.77        164470.71              1               0\n",
       "42   23640.93        96189.63        148001.11              0               0\n",
       "43   15505.73       127382.30         35534.17              0               1\n",
       "44   22177.74       154806.14         28334.72              0               0\n",
       "45    1000.23       124153.04          1903.93              0               1\n",
       "46    1315.46       115816.21        297114.46              1               0\n",
       "47       0.00       135426.92             0.00              0               0\n",
       "48     542.05        51743.15             0.00              0               1\n",
       "49       0.00       116983.80         45173.06              0               0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent=dataset[['R&D Spend', 'Administration', 'Marketing Spend', 'State_Florida', 'State_New York']]\n",
    "independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b689fa-ff4f-4ca9-ab11-03b8f83439b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156991.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>156122.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>155752.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>152211.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>149759.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>146121.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>144259.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>141585.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>134307.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>132602.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>129917.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>126992.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>125370.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>124266.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>122776.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>118474.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>111313.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>110352.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>108733.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>108552.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>107404.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>105733.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>105008.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>103282.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>101004.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>99937.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>97483.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>97427.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>96778.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>96712.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>96479.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>90708.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>89949.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>81229.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>81005.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>78239.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>77798.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>71498.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>69758.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>65200.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>64926.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>49490.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>42559.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>35673.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>14681.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Profit\n",
       "0   192261.83\n",
       "1   191792.06\n",
       "2   191050.39\n",
       "3   182901.99\n",
       "4   166187.94\n",
       "5   156991.12\n",
       "6   156122.51\n",
       "7   155752.60\n",
       "8   152211.77\n",
       "9   149759.96\n",
       "10  146121.95\n",
       "11  144259.40\n",
       "12  141585.52\n",
       "13  134307.35\n",
       "14  132602.65\n",
       "15  129917.04\n",
       "16  126992.93\n",
       "17  125370.37\n",
       "18  124266.90\n",
       "19  122776.86\n",
       "20  118474.03\n",
       "21  111313.02\n",
       "22  110352.25\n",
       "23  108733.99\n",
       "24  108552.04\n",
       "25  107404.34\n",
       "26  105733.54\n",
       "27  105008.31\n",
       "28  103282.38\n",
       "29  101004.64\n",
       "30   99937.59\n",
       "31   97483.56\n",
       "32   97427.84\n",
       "33   96778.92\n",
       "34   96712.80\n",
       "35   96479.51\n",
       "36   90708.19\n",
       "37   89949.14\n",
       "38   81229.06\n",
       "39   81005.76\n",
       "40   78239.91\n",
       "41   77798.83\n",
       "42   71498.49\n",
       "43   69758.98\n",
       "44   65200.33\n",
       "45   64926.08\n",
       "46   49490.75\n",
       "47   42559.73\n",
       "48   35673.41\n",
       "49   14681.40"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent = dataset[['Profit']]\n",
    "dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d056733e-8a46-44eb-ae8b-07192857c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac3873a1-7bdd-4e7c-9bc9-a86eadc27ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hxtreme\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=AdaBoostRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.5, 0.7, 1.0],\n",
       "                         &#x27;loss&#x27;: [&#x27;linear&#x27;, &#x27;square&#x27;, &#x27;exponential&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 30, 40, 50]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=AdaBoostRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.5, 0.7, 1.0],\n",
       "                         &#x27;loss&#x27;: [&#x27;linear&#x27;, &#x27;square&#x27;, &#x27;exponential&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 30, 40, 50]},\n",
       "             verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: AdaBoostRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostRegressor(loss=&#x27;square&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;AdaBoostRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.AdaBoostRegressor.html\">?<span>Documentation for AdaBoostRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostRegressor(loss=&#x27;square&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=AdaBoostRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.5, 0.7, 1.0],\n",
       "                         'loss': ['linear', 'square', 'exponential'],\n",
       "                         'n_estimators': [10, 20, 30, 40, 50]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "param_grid = {'loss':['linear','square','exponential'],\n",
    "              'learning_rate':[0.5,0.7,1.0],'n_estimators':[10,20,30,40,50]}\n",
    "grid = GridSearchCV(AdaBoostRegressor(),param_grid,verbose=3,n_jobs=-1)\n",
    "grid.fit(independent,dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "692d1153-1004-4a59-9a53-dc2310b0b184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1.0, 'loss': 'square', 'n_estimators': 50}\n",
      "{'mean_fit_time': array([0.10739398, 0.16078916, 0.17378917, 0.23318515, 0.26698322,\n",
      "       0.05839663, 0.11999273, 0.17552752, 0.26358414, 0.24678531,\n",
      "       0.05919623, 0.11039205, 0.15519094, 0.21418676, 0.24358554,\n",
      "       0.05779567, 0.10539341, 0.15039072, 0.22500224, 0.29558182,\n",
      "       0.06459599, 0.12519193, 0.15227818, 0.19778738, 0.24478455,\n",
      "       0.05839572, 0.1362143 , 0.31138229, 0.28619533, 0.25498462,\n",
      "       0.05839548, 0.10839329, 0.17738867, 0.25998387, 0.26218357,\n",
      "       0.073947  , 0.11859212, 0.15799026, 0.22898612, 0.26729803,\n",
      "       0.06039639, 0.1075932 , 0.16278987, 0.20578785, 0.30130253]), 'std_fit_time': array([0.02047582, 0.02099942, 0.01393301, 0.00591245, 0.01359362,\n",
      "       0.00412763, 0.00701336, 0.00997823, 0.0305963 , 0.00805938,\n",
      "       0.00278578, 0.00646841, 0.0049556 , 0.01313535, 0.00241649,\n",
      "       0.0024818 , 0.00307179, 0.00462949, 0.02200044, 0.02203093,\n",
      "       0.00581672, 0.00342927, 0.00363638, 0.00381546, 0.00523062,\n",
      "       0.00257758, 0.041241  , 0.01703654, 0.04155308, 0.00641822,\n",
      "       0.00265331, 0.00279999, 0.02200379, 0.03702757, 0.02291879,\n",
      "       0.01135914, 0.0048001 , 0.01159238, 0.00831805, 0.01317876,\n",
      "       0.00440868, 0.00233263, 0.00696858, 0.00574135, 0.0206997 ]), 'mean_score_time': array([0.01859722, 0.0228004 , 0.02039819, 0.02719836, 0.02759848,\n",
      "       0.01239886, 0.01959844, 0.02619848, 0.0236125 , 0.0268106 ,\n",
      "       0.0118217 , 0.01579957, 0.02019825, 0.02379842, 0.02781868,\n",
      "       0.01179991, 0.01559844, 0.01959801, 0.0308073 , 0.03099861,\n",
      "       0.01299963, 0.01819868, 0.0191988 , 0.02259889, 0.02719855,\n",
      "       0.01219964, 0.05237541, 0.04139414, 0.03078556, 0.02679825,\n",
      "       0.01319923, 0.01719971, 0.02339883, 0.0247982 , 0.03079853,\n",
      "       0.01299925, 0.01879911, 0.01979842, 0.02639842, 0.02708397,\n",
      "       0.01379862, 0.01839852, 0.01939878, 0.02419786, 0.03179946]), 'std_score_time': array([0.0044992 , 0.003763  , 0.00135534, 0.00248188, 0.00101959,\n",
      "       0.00101922, 0.00185456, 0.0057755 , 0.00121596, 0.00115755,\n",
      "       0.00072606, 0.00116635, 0.00116587, 0.00132654, 0.00096384,\n",
      "       0.00074886, 0.00049   , 0.0011996 , 0.00641422, 0.0023659 ,\n",
      "       0.00126588, 0.00396955, 0.00074854, 0.0004899 , 0.00193858,\n",
      "       0.00116573, 0.02843131, 0.01678508, 0.01115292, 0.00116589,\n",
      "       0.00146982, 0.00116619, 0.00436326, 0.00365522, 0.00630546,\n",
      "       0.00063286, 0.00203927, 0.00074798, 0.00279989, 0.00081117,\n",
      "       0.00146954, 0.00382605, 0.00048951, 0.00159999, 0.01416129]), 'param_learning_rate': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 1.0, 1.0, 1.0,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
      "                   1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value=1e+20), 'param_loss': masked_array(data=['linear', 'linear', 'linear', 'linear', 'linear',\n",
      "                   'square', 'square', 'square', 'square', 'square',\n",
      "                   'exponential', 'exponential', 'exponential',\n",
      "                   'exponential', 'exponential', 'linear', 'linear',\n",
      "                   'linear', 'linear', 'linear', 'square', 'square',\n",
      "                   'square', 'square', 'square', 'exponential',\n",
      "                   'exponential', 'exponential', 'exponential',\n",
      "                   'exponential', 'linear', 'linear', 'linear', 'linear',\n",
      "                   'linear', 'square', 'square', 'square', 'square',\n",
      "                   'square', 'exponential', 'exponential', 'exponential',\n",
      "                   'exponential', 'exponential'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[10, 20, 30, 40, 50, 10, 20, 30, 40, 50, 10, 20, 30, 40,\n",
      "                   50, 10, 20, 30, 40, 50, 10, 20, 30, 40, 50, 10, 20, 30,\n",
      "                   40, 50, 10, 20, 30, 40, 50, 10, 20, 30, 40, 50, 10, 20,\n",
      "                   30, 40, 50],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value=999999), 'params': [{'learning_rate': 0.5, 'loss': 'linear', 'n_estimators': 10}, {'learning_rate': 0.5, 'loss': 'linear', 'n_estimators': 20}, {'learning_rate': 0.5, 'loss': 'linear', 'n_estimators': 30}, {'learning_rate': 0.5, 'loss': 'linear', 'n_estimators': 40}, {'learning_rate': 0.5, 'loss': 'linear', 'n_estimators': 50}, {'learning_rate': 0.5, 'loss': 'square', 'n_estimators': 10}, {'learning_rate': 0.5, 'loss': 'square', 'n_estimators': 20}, {'learning_rate': 0.5, 'loss': 'square', 'n_estimators': 30}, {'learning_rate': 0.5, 'loss': 'square', 'n_estimators': 40}, {'learning_rate': 0.5, 'loss': 'square', 'n_estimators': 50}, {'learning_rate': 0.5, 'loss': 'exponential', 'n_estimators': 10}, {'learning_rate': 0.5, 'loss': 'exponential', 'n_estimators': 20}, {'learning_rate': 0.5, 'loss': 'exponential', 'n_estimators': 30}, {'learning_rate': 0.5, 'loss': 'exponential', 'n_estimators': 40}, {'learning_rate': 0.5, 'loss': 'exponential', 'n_estimators': 50}, {'learning_rate': 0.7, 'loss': 'linear', 'n_estimators': 10}, {'learning_rate': 0.7, 'loss': 'linear', 'n_estimators': 20}, {'learning_rate': 0.7, 'loss': 'linear', 'n_estimators': 30}, {'learning_rate': 0.7, 'loss': 'linear', 'n_estimators': 40}, {'learning_rate': 0.7, 'loss': 'linear', 'n_estimators': 50}, {'learning_rate': 0.7, 'loss': 'square', 'n_estimators': 10}, {'learning_rate': 0.7, 'loss': 'square', 'n_estimators': 20}, {'learning_rate': 0.7, 'loss': 'square', 'n_estimators': 30}, {'learning_rate': 0.7, 'loss': 'square', 'n_estimators': 40}, {'learning_rate': 0.7, 'loss': 'square', 'n_estimators': 50}, {'learning_rate': 0.7, 'loss': 'exponential', 'n_estimators': 10}, {'learning_rate': 0.7, 'loss': 'exponential', 'n_estimators': 20}, {'learning_rate': 0.7, 'loss': 'exponential', 'n_estimators': 30}, {'learning_rate': 0.7, 'loss': 'exponential', 'n_estimators': 40}, {'learning_rate': 0.7, 'loss': 'exponential', 'n_estimators': 50}, {'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 10}, {'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 20}, {'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 30}, {'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 40}, {'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50}, {'learning_rate': 1.0, 'loss': 'square', 'n_estimators': 10}, {'learning_rate': 1.0, 'loss': 'square', 'n_estimators': 20}, {'learning_rate': 1.0, 'loss': 'square', 'n_estimators': 30}, {'learning_rate': 1.0, 'loss': 'square', 'n_estimators': 40}, {'learning_rate': 1.0, 'loss': 'square', 'n_estimators': 50}, {'learning_rate': 1.0, 'loss': 'exponential', 'n_estimators': 10}, {'learning_rate': 1.0, 'loss': 'exponential', 'n_estimators': 20}, {'learning_rate': 1.0, 'loss': 'exponential', 'n_estimators': 30}, {'learning_rate': 1.0, 'loss': 'exponential', 'n_estimators': 40}, {'learning_rate': 1.0, 'loss': 'exponential', 'n_estimators': 50}], 'split0_test_score': array([-4.75386688, -4.78667755, -4.94105911, -4.6115247 , -4.70212015,\n",
      "       -6.09616482, -4.45878944, -4.78137172, -4.31961066, -4.37474705,\n",
      "       -4.82185697, -4.81756642, -5.20065658, -4.68412747, -4.71754911,\n",
      "       -3.81343459, -5.38649195, -4.37467165, -4.92858122, -4.68933246,\n",
      "       -5.67634076, -4.59684648, -4.69439622, -3.92647968, -4.84820583,\n",
      "       -5.02372231, -4.93736189, -4.880856  , -4.96974162, -5.19247967,\n",
      "       -4.2494542 , -5.28926035, -4.26335702, -4.42622624, -4.70701648,\n",
      "       -4.57106017, -4.03390185, -4.29293384, -4.09484506, -4.34089587,\n",
      "       -4.45215464, -4.7230882 , -5.02968724, -4.76988173, -4.72233498]), 'split1_test_score': array([-6.19694911, -5.30494893, -4.70248089, -5.61843618, -5.50496464,\n",
      "       -6.82903809, -4.92883723, -5.71748597, -4.72027626, -4.85412602,\n",
      "       -5.57980219, -6.36840288, -4.76608279, -5.00219086, -4.0215486 ,\n",
      "       -5.43456145, -4.68944932, -4.58804438, -4.58231247, -4.98607697,\n",
      "       -6.87954952, -6.26149549, -4.93103041, -5.71834402, -4.22691542,\n",
      "       -5.42596759, -4.08563325, -6.07092929, -4.17500965, -4.40768969,\n",
      "       -3.90631494, -5.75827605, -5.10839526, -4.701063  , -4.61630547,\n",
      "       -4.5834997 , -4.99900416, -4.64043444, -4.92022844, -4.52250522,\n",
      "       -6.54470815, -4.46157411, -7.46137328, -4.52607186, -4.13269189]), 'split2_test_score': array([-12.06347275, -11.62367794,  -8.56564766,  -7.10650486,\n",
      "        -7.59283177, -15.04214514,  -8.48221729,  -8.08422448,\n",
      "        -7.59100071,  -6.72773382, -13.41796789,  -8.06638381,\n",
      "        -8.73753159,  -8.66609998,  -8.90179769, -12.8273533 ,\n",
      "        -9.3966611 ,  -9.34155841,  -6.29574924,  -7.2271952 ,\n",
      "       -10.89622107,  -8.33405055,  -6.68919278,  -9.21791371,\n",
      "       -10.35551113,  -8.97648099, -13.15488793, -11.61448853,\n",
      "        -8.02490184,  -6.91328294, -13.37629332,  -9.88292398,\n",
      "       -11.24055994,  -6.44068453,  -5.97432018,  -7.18488203,\n",
      "        -7.52195703,  -8.06950546,  -8.39233331,  -5.71335905,\n",
      "        -5.84190778,  -9.74620276,  -8.00461098,  -7.63506182,\n",
      "        -7.61843227]), 'split3_test_score': array([-3.88216526, -4.18683468, -2.86820139, -3.51616681, -3.2069929 ,\n",
      "       -3.10689127, -3.04877882, -4.95637093, -3.90635416, -3.48484039,\n",
      "       -4.52416422, -4.34406998, -4.41675004, -3.1615031 , -3.06699609,\n",
      "       -2.45407044, -4.50883783, -4.73262648, -3.43690812, -4.01541609,\n",
      "       -3.83928802, -4.41259807, -3.63686094, -3.06290343, -4.49877285,\n",
      "       -2.73813954, -3.7264384 , -3.6990926 , -3.64099505, -4.03466185,\n",
      "       -3.41934073, -2.99992549, -3.95703243, -3.47344605, -3.24514274,\n",
      "       -2.87755129, -3.35753806, -3.02838216, -3.21555722, -2.43814507,\n",
      "       -2.45347477, -3.43476207, -3.50890584, -3.02130672, -2.8352869 ]), 'split4_test_score': array([-2.61594198, -2.4632385 , -2.42407655, -2.30167086, -3.10318876,\n",
      "       -2.4060295 , -2.53344978, -2.08062208, -2.53638967, -2.77216123,\n",
      "       -2.94847384, -2.77273199, -2.71644031, -2.25739798, -2.44961102,\n",
      "       -3.0412074 , -2.45066461, -2.92611724, -2.64095759, -3.19798146,\n",
      "       -3.46559983, -3.27791112, -1.87720129, -2.63101505, -2.74940547,\n",
      "       -3.4621942 , -2.92605155, -2.62507435, -2.50217169, -2.4473781 ,\n",
      "       -3.16703142, -2.86926664, -2.24800584, -2.98208914, -2.41060322,\n",
      "       -3.074147  , -2.21181068, -2.72101103, -2.77484513, -3.04068003,\n",
      "       -2.54931314, -2.67027616, -2.23591967, -3.10318706, -2.98775796]), 'mean_test_score': array([-5.90247919, -5.67307552, -4.70029312, -4.63086068, -4.82201964,\n",
      "       -6.69605376, -4.69041451, -5.12401504, -4.61472629, -4.4427217 ,\n",
      "       -6.25845302, -5.27383101, -5.16749226, -4.75426388, -4.6315005 ,\n",
      "       -5.51412544, -5.28642096, -5.19260363, -4.37690173, -4.82320044,\n",
      "       -6.15139984, -5.37658034, -4.36573633, -4.91133118, -5.33576214,\n",
      "       -5.12530093, -5.7660746 , -5.77808815, -4.66256397, -4.59909845,\n",
      "       -5.62368692, -5.3599305 , -5.3634701 , -4.40470179, -4.19067762,\n",
      "       -4.45822804, -4.42484236, -4.55045339, -4.67956183, -4.01111705,\n",
      "       -4.3683117 , -5.00718066, -5.2480994 , -4.61110184, -4.4593008 ]), 'std_test_score': array([3.29383848, 3.12547127, 2.16963871, 1.65964822, 1.6565555 ,\n",
      "       4.50158169, 2.08977168, 1.92472322, 1.65998299, 1.34933045,\n",
      "       3.68094412, 1.80690719, 1.97376188, 2.19727444, 2.27258441,\n",
      "       3.79107483, 2.27625187, 2.17241202, 1.25901626, 1.35036976,\n",
      "       2.67688604, 1.75905452, 1.58430367, 2.39934917, 2.60978635,\n",
      "       2.16318146, 3.75049482, 3.1374534 , 1.86270132, 1.46237325,\n",
      "       3.8944855 , 2.54535552, 3.08219666, 1.19369871, 1.24031018,\n",
      "       1.54125179, 1.79506341, 1.90376997, 1.99778585, 1.15619104,\n",
      "       1.6667677 , 2.48073974, 2.22002983, 1.67200662, 1.72967231]), 'rank_test_score': array([42, 39, 20, 15, 22, 45, 19, 26, 14,  8, 44, 31, 28, 21, 16, 37, 32,\n",
      "       29,  5, 23, 43, 36,  3, 24, 33, 27, 40, 41, 17, 12, 38, 34, 35,  6,\n",
      "        2,  9,  7, 11, 18,  1,  4, 25, 30, 13, 10])}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "re=grid.cv_results_\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "134955c8-5ac7-4cc4-94fa-bb387813c94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best R_score value Parameters:{'learning_rate': 1.0, 'loss': 'square', 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best R_score value Parameters:{}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd67b055-c084-49c8-8f65-82314563034a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.107394</td>\n",
       "      <td>0.020476</td>\n",
       "      <td>0.018597</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-4.753867</td>\n",
       "      <td>-6.196949</td>\n",
       "      <td>-12.063473</td>\n",
       "      <td>-3.882165</td>\n",
       "      <td>-2.615942</td>\n",
       "      <td>-5.902479</td>\n",
       "      <td>3.293838</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.160789</td>\n",
       "      <td>0.020999</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-4.786678</td>\n",
       "      <td>-5.304949</td>\n",
       "      <td>-11.623678</td>\n",
       "      <td>-4.186835</td>\n",
       "      <td>-2.463238</td>\n",
       "      <td>-5.673076</td>\n",
       "      <td>3.125471</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.173789</td>\n",
       "      <td>0.013933</td>\n",
       "      <td>0.020398</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-4.941059</td>\n",
       "      <td>-4.702481</td>\n",
       "      <td>-8.565648</td>\n",
       "      <td>-2.868201</td>\n",
       "      <td>-2.424077</td>\n",
       "      <td>-4.700293</td>\n",
       "      <td>2.169639</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.233185</td>\n",
       "      <td>0.005912</td>\n",
       "      <td>0.027198</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-4.611525</td>\n",
       "      <td>-5.618436</td>\n",
       "      <td>-7.106505</td>\n",
       "      <td>-3.516167</td>\n",
       "      <td>-2.301671</td>\n",
       "      <td>-4.630861</td>\n",
       "      <td>1.659648</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266983</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>0.027598</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-4.702120</td>\n",
       "      <td>-5.504965</td>\n",
       "      <td>-7.592832</td>\n",
       "      <td>-3.206993</td>\n",
       "      <td>-3.103189</td>\n",
       "      <td>-4.822020</td>\n",
       "      <td>1.656555</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.058397</td>\n",
       "      <td>0.004128</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.5</td>\n",
       "      <td>square</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-6.096165</td>\n",
       "      <td>-6.829038</td>\n",
       "      <td>-15.042145</td>\n",
       "      <td>-3.106891</td>\n",
       "      <td>-2.406029</td>\n",
       "      <td>-6.696054</td>\n",
       "      <td>4.501582</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.119993</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.019598</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.5</td>\n",
       "      <td>square</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-4.458789</td>\n",
       "      <td>-4.928837</td>\n",
       "      <td>-8.482217</td>\n",
       "      <td>-3.048779</td>\n",
       "      <td>-2.533450</td>\n",
       "      <td>-4.690415</td>\n",
       "      <td>2.089772</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.175528</td>\n",
       "      <td>0.009978</td>\n",
       "      <td>0.026198</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.5</td>\n",
       "      <td>square</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-4.781372</td>\n",
       "      <td>-5.717486</td>\n",
       "      <td>-8.084224</td>\n",
       "      <td>-4.956371</td>\n",
       "      <td>-2.080622</td>\n",
       "      <td>-5.124015</td>\n",
       "      <td>1.924723</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.263584</td>\n",
       "      <td>0.030596</td>\n",
       "      <td>0.023612</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.5</td>\n",
       "      <td>square</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-4.319611</td>\n",
       "      <td>-4.720276</td>\n",
       "      <td>-7.591001</td>\n",
       "      <td>-3.906354</td>\n",
       "      <td>-2.536390</td>\n",
       "      <td>-4.614726</td>\n",
       "      <td>1.659983</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.246785</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>0.026811</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.5</td>\n",
       "      <td>square</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-4.374747</td>\n",
       "      <td>-4.854126</td>\n",
       "      <td>-6.727734</td>\n",
       "      <td>-3.484840</td>\n",
       "      <td>-2.772161</td>\n",
       "      <td>-4.442722</td>\n",
       "      <td>1.349330</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.059196</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.011822</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.5</td>\n",
       "      <td>exponential</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'exponential', ...</td>\n",
       "      <td>-4.821857</td>\n",
       "      <td>-5.579802</td>\n",
       "      <td>-13.417968</td>\n",
       "      <td>-4.524164</td>\n",
       "      <td>-2.948474</td>\n",
       "      <td>-6.258453</td>\n",
       "      <td>3.680944</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.110392</td>\n",
       "      <td>0.006468</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.5</td>\n",
       "      <td>exponential</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'exponential', ...</td>\n",
       "      <td>-4.817566</td>\n",
       "      <td>-6.368403</td>\n",
       "      <td>-8.066384</td>\n",
       "      <td>-4.344070</td>\n",
       "      <td>-2.772732</td>\n",
       "      <td>-5.273831</td>\n",
       "      <td>1.806907</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.155191</td>\n",
       "      <td>0.004956</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.5</td>\n",
       "      <td>exponential</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'exponential', ...</td>\n",
       "      <td>-5.200657</td>\n",
       "      <td>-4.766083</td>\n",
       "      <td>-8.737532</td>\n",
       "      <td>-4.416750</td>\n",
       "      <td>-2.716440</td>\n",
       "      <td>-5.167492</td>\n",
       "      <td>1.973762</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.214187</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>0.023798</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.5</td>\n",
       "      <td>exponential</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'exponential', ...</td>\n",
       "      <td>-4.684127</td>\n",
       "      <td>-5.002191</td>\n",
       "      <td>-8.666100</td>\n",
       "      <td>-3.161503</td>\n",
       "      <td>-2.257398</td>\n",
       "      <td>-4.754264</td>\n",
       "      <td>2.197274</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.243586</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.027819</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.5</td>\n",
       "      <td>exponential</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'exponential', ...</td>\n",
       "      <td>-4.717549</td>\n",
       "      <td>-4.021549</td>\n",
       "      <td>-8.901798</td>\n",
       "      <td>-3.066996</td>\n",
       "      <td>-2.449611</td>\n",
       "      <td>-4.631500</td>\n",
       "      <td>2.272584</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.057796</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.7</td>\n",
       "      <td>linear</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-3.813435</td>\n",
       "      <td>-5.434561</td>\n",
       "      <td>-12.827353</td>\n",
       "      <td>-2.454070</td>\n",
       "      <td>-3.041207</td>\n",
       "      <td>-5.514125</td>\n",
       "      <td>3.791075</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.105393</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.015598</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.7</td>\n",
       "      <td>linear</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-5.386492</td>\n",
       "      <td>-4.689449</td>\n",
       "      <td>-9.396661</td>\n",
       "      <td>-4.508838</td>\n",
       "      <td>-2.450665</td>\n",
       "      <td>-5.286421</td>\n",
       "      <td>2.276252</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.150391</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.019598</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.7</td>\n",
       "      <td>linear</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-4.374672</td>\n",
       "      <td>-4.588044</td>\n",
       "      <td>-9.341558</td>\n",
       "      <td>-4.732626</td>\n",
       "      <td>-2.926117</td>\n",
       "      <td>-5.192604</td>\n",
       "      <td>2.172412</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.225002</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.030807</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.7</td>\n",
       "      <td>linear</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-4.928581</td>\n",
       "      <td>-4.582312</td>\n",
       "      <td>-6.295749</td>\n",
       "      <td>-3.436908</td>\n",
       "      <td>-2.640958</td>\n",
       "      <td>-4.376902</td>\n",
       "      <td>1.259016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.295582</td>\n",
       "      <td>0.022031</td>\n",
       "      <td>0.030999</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.7</td>\n",
       "      <td>linear</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-4.689332</td>\n",
       "      <td>-4.986077</td>\n",
       "      <td>-7.227195</td>\n",
       "      <td>-4.015416</td>\n",
       "      <td>-3.197981</td>\n",
       "      <td>-4.823200</td>\n",
       "      <td>1.350370</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.064596</td>\n",
       "      <td>0.005817</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.7</td>\n",
       "      <td>square</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-5.676341</td>\n",
       "      <td>-6.879550</td>\n",
       "      <td>-10.896221</td>\n",
       "      <td>-3.839288</td>\n",
       "      <td>-3.465600</td>\n",
       "      <td>-6.151400</td>\n",
       "      <td>2.676886</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.125192</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.018199</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>0.7</td>\n",
       "      <td>square</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-4.596846</td>\n",
       "      <td>-6.261495</td>\n",
       "      <td>-8.334051</td>\n",
       "      <td>-4.412598</td>\n",
       "      <td>-3.277911</td>\n",
       "      <td>-5.376580</td>\n",
       "      <td>1.759055</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.152278</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.019199</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.7</td>\n",
       "      <td>square</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-4.694396</td>\n",
       "      <td>-4.931030</td>\n",
       "      <td>-6.689193</td>\n",
       "      <td>-3.636861</td>\n",
       "      <td>-1.877201</td>\n",
       "      <td>-4.365736</td>\n",
       "      <td>1.584304</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.197787</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.022599</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.7</td>\n",
       "      <td>square</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-3.926480</td>\n",
       "      <td>-5.718344</td>\n",
       "      <td>-9.217914</td>\n",
       "      <td>-3.062903</td>\n",
       "      <td>-2.631015</td>\n",
       "      <td>-4.911331</td>\n",
       "      <td>2.399349</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.244785</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.027199</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.7</td>\n",
       "      <td>square</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-4.848206</td>\n",
       "      <td>-4.226915</td>\n",
       "      <td>-10.355511</td>\n",
       "      <td>-4.498773</td>\n",
       "      <td>-2.749405</td>\n",
       "      <td>-5.335762</td>\n",
       "      <td>2.609786</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.058396</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.7</td>\n",
       "      <td>exponential</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'exponential', ...</td>\n",
       "      <td>-5.023722</td>\n",
       "      <td>-5.425968</td>\n",
       "      <td>-8.976481</td>\n",
       "      <td>-2.738140</td>\n",
       "      <td>-3.462194</td>\n",
       "      <td>-5.125301</td>\n",
       "      <td>2.163181</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.136214</td>\n",
       "      <td>0.041241</td>\n",
       "      <td>0.052375</td>\n",
       "      <td>0.028431</td>\n",
       "      <td>0.7</td>\n",
       "      <td>exponential</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'exponential', ...</td>\n",
       "      <td>-4.937362</td>\n",
       "      <td>-4.085633</td>\n",
       "      <td>-13.154888</td>\n",
       "      <td>-3.726438</td>\n",
       "      <td>-2.926052</td>\n",
       "      <td>-5.766075</td>\n",
       "      <td>3.750495</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.311382</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>0.041394</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>0.7</td>\n",
       "      <td>exponential</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'exponential', ...</td>\n",
       "      <td>-4.880856</td>\n",
       "      <td>-6.070929</td>\n",
       "      <td>-11.614489</td>\n",
       "      <td>-3.699093</td>\n",
       "      <td>-2.625074</td>\n",
       "      <td>-5.778088</td>\n",
       "      <td>3.137453</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.286195</td>\n",
       "      <td>0.041553</td>\n",
       "      <td>0.030786</td>\n",
       "      <td>0.011153</td>\n",
       "      <td>0.7</td>\n",
       "      <td>exponential</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'exponential', ...</td>\n",
       "      <td>-4.969742</td>\n",
       "      <td>-4.175010</td>\n",
       "      <td>-8.024902</td>\n",
       "      <td>-3.640995</td>\n",
       "      <td>-2.502172</td>\n",
       "      <td>-4.662564</td>\n",
       "      <td>1.862701</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.254985</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.026798</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.7</td>\n",
       "      <td>exponential</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'exponential', ...</td>\n",
       "      <td>-5.192480</td>\n",
       "      <td>-4.407690</td>\n",
       "      <td>-6.913283</td>\n",
       "      <td>-4.034662</td>\n",
       "      <td>-2.447378</td>\n",
       "      <td>-4.599098</td>\n",
       "      <td>1.462373</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.058395</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.013199</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-4.249454</td>\n",
       "      <td>-3.906315</td>\n",
       "      <td>-13.376293</td>\n",
       "      <td>-3.419341</td>\n",
       "      <td>-3.167031</td>\n",
       "      <td>-5.623687</td>\n",
       "      <td>3.894485</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.108393</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-5.289260</td>\n",
       "      <td>-5.758276</td>\n",
       "      <td>-9.882924</td>\n",
       "      <td>-2.999925</td>\n",
       "      <td>-2.869267</td>\n",
       "      <td>-5.359931</td>\n",
       "      <td>2.545356</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.177389</td>\n",
       "      <td>0.022004</td>\n",
       "      <td>0.023399</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-4.263357</td>\n",
       "      <td>-5.108395</td>\n",
       "      <td>-11.240560</td>\n",
       "      <td>-3.957032</td>\n",
       "      <td>-2.248006</td>\n",
       "      <td>-5.363470</td>\n",
       "      <td>3.082197</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.259984</td>\n",
       "      <td>0.037028</td>\n",
       "      <td>0.024798</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>1.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-4.426226</td>\n",
       "      <td>-4.701063</td>\n",
       "      <td>-6.440685</td>\n",
       "      <td>-3.473446</td>\n",
       "      <td>-2.982089</td>\n",
       "      <td>-4.404702</td>\n",
       "      <td>1.193699</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.262184</td>\n",
       "      <td>0.022919</td>\n",
       "      <td>0.030799</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>-4.707016</td>\n",
       "      <td>-4.616305</td>\n",
       "      <td>-5.974320</td>\n",
       "      <td>-3.245143</td>\n",
       "      <td>-2.410603</td>\n",
       "      <td>-4.190678</td>\n",
       "      <td>1.240310</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.073947</td>\n",
       "      <td>0.011359</td>\n",
       "      <td>0.012999</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>square</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-4.571060</td>\n",
       "      <td>-4.583500</td>\n",
       "      <td>-7.184882</td>\n",
       "      <td>-2.877551</td>\n",
       "      <td>-3.074147</td>\n",
       "      <td>-4.458228</td>\n",
       "      <td>1.541252</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.118592</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>square</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-4.033902</td>\n",
       "      <td>-4.999004</td>\n",
       "      <td>-7.521957</td>\n",
       "      <td>-3.357538</td>\n",
       "      <td>-2.211811</td>\n",
       "      <td>-4.424842</td>\n",
       "      <td>1.795063</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.157990</td>\n",
       "      <td>0.011592</td>\n",
       "      <td>0.019798</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>1.0</td>\n",
       "      <td>square</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-4.292934</td>\n",
       "      <td>-4.640434</td>\n",
       "      <td>-8.069505</td>\n",
       "      <td>-3.028382</td>\n",
       "      <td>-2.721011</td>\n",
       "      <td>-4.550453</td>\n",
       "      <td>1.903770</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.228986</td>\n",
       "      <td>0.008318</td>\n",
       "      <td>0.026398</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>square</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-4.094845</td>\n",
       "      <td>-4.920228</td>\n",
       "      <td>-8.392333</td>\n",
       "      <td>-3.215557</td>\n",
       "      <td>-2.774845</td>\n",
       "      <td>-4.679562</td>\n",
       "      <td>1.997786</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.267298</td>\n",
       "      <td>0.013179</td>\n",
       "      <td>0.027084</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>square</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'square', 'n_es...</td>\n",
       "      <td>-4.340896</td>\n",
       "      <td>-4.522505</td>\n",
       "      <td>-5.713359</td>\n",
       "      <td>-2.438145</td>\n",
       "      <td>-3.040680</td>\n",
       "      <td>-4.011117</td>\n",
       "      <td>1.156191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.060396</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'exponential', ...</td>\n",
       "      <td>-4.452155</td>\n",
       "      <td>-6.544708</td>\n",
       "      <td>-5.841908</td>\n",
       "      <td>-2.453475</td>\n",
       "      <td>-2.549313</td>\n",
       "      <td>-4.368312</td>\n",
       "      <td>1.666768</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.107593</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.018399</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'exponential', ...</td>\n",
       "      <td>-4.723088</td>\n",
       "      <td>-4.461574</td>\n",
       "      <td>-9.746203</td>\n",
       "      <td>-3.434762</td>\n",
       "      <td>-2.670276</td>\n",
       "      <td>-5.007181</td>\n",
       "      <td>2.480740</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.162790</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.019399</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'exponential', ...</td>\n",
       "      <td>-5.029687</td>\n",
       "      <td>-7.461373</td>\n",
       "      <td>-8.004611</td>\n",
       "      <td>-3.508906</td>\n",
       "      <td>-2.235920</td>\n",
       "      <td>-5.248099</td>\n",
       "      <td>2.220030</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.205788</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.024198</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'exponential', ...</td>\n",
       "      <td>-4.769882</td>\n",
       "      <td>-4.526072</td>\n",
       "      <td>-7.635062</td>\n",
       "      <td>-3.021307</td>\n",
       "      <td>-3.103187</td>\n",
       "      <td>-4.611102</td>\n",
       "      <td>1.672007</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.301303</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.031799</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'exponential', ...</td>\n",
       "      <td>-4.722335</td>\n",
       "      <td>-4.132692</td>\n",
       "      <td>-7.618432</td>\n",
       "      <td>-2.835287</td>\n",
       "      <td>-2.987758</td>\n",
       "      <td>-4.459301</td>\n",
       "      <td>1.729672</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.107394      0.020476         0.018597        0.004499   \n",
       "1        0.160789      0.020999         0.022800        0.003763   \n",
       "2        0.173789      0.013933         0.020398        0.001355   \n",
       "3        0.233185      0.005912         0.027198        0.002482   \n",
       "4        0.266983      0.013594         0.027598        0.001020   \n",
       "5        0.058397      0.004128         0.012399        0.001019   \n",
       "6        0.119993      0.007013         0.019598        0.001855   \n",
       "7        0.175528      0.009978         0.026198        0.005776   \n",
       "8        0.263584      0.030596         0.023612        0.001216   \n",
       "9        0.246785      0.008059         0.026811        0.001158   \n",
       "10       0.059196      0.002786         0.011822        0.000726   \n",
       "11       0.110392      0.006468         0.015800        0.001166   \n",
       "12       0.155191      0.004956         0.020198        0.001166   \n",
       "13       0.214187      0.013135         0.023798        0.001327   \n",
       "14       0.243586      0.002416         0.027819        0.000964   \n",
       "15       0.057796      0.002482         0.011800        0.000749   \n",
       "16       0.105393      0.003072         0.015598        0.000490   \n",
       "17       0.150391      0.004629         0.019598        0.001200   \n",
       "18       0.225002      0.022000         0.030807        0.006414   \n",
       "19       0.295582      0.022031         0.030999        0.002366   \n",
       "20       0.064596      0.005817         0.013000        0.001266   \n",
       "21       0.125192      0.003429         0.018199        0.003970   \n",
       "22       0.152278      0.003636         0.019199        0.000749   \n",
       "23       0.197787      0.003815         0.022599        0.000490   \n",
       "24       0.244785      0.005231         0.027199        0.001939   \n",
       "25       0.058396      0.002578         0.012200        0.001166   \n",
       "26       0.136214      0.041241         0.052375        0.028431   \n",
       "27       0.311382      0.017037         0.041394        0.016785   \n",
       "28       0.286195      0.041553         0.030786        0.011153   \n",
       "29       0.254985      0.006418         0.026798        0.001166   \n",
       "30       0.058395      0.002653         0.013199        0.001470   \n",
       "31       0.108393      0.002800         0.017200        0.001166   \n",
       "32       0.177389      0.022004         0.023399        0.004363   \n",
       "33       0.259984      0.037028         0.024798        0.003655   \n",
       "34       0.262184      0.022919         0.030799        0.006305   \n",
       "35       0.073947      0.011359         0.012999        0.000633   \n",
       "36       0.118592      0.004800         0.018799        0.002039   \n",
       "37       0.157990      0.011592         0.019798        0.000748   \n",
       "38       0.228986      0.008318         0.026398        0.002800   \n",
       "39       0.267298      0.013179         0.027084        0.000811   \n",
       "40       0.060396      0.004409         0.013799        0.001470   \n",
       "41       0.107593      0.002333         0.018399        0.003826   \n",
       "42       0.162790      0.006969         0.019399        0.000490   \n",
       "43       0.205788      0.005741         0.024198        0.001600   \n",
       "44       0.301303      0.020700         0.031799        0.014161   \n",
       "\n",
       "    param_learning_rate   param_loss  param_n_estimators  \\\n",
       "0                   0.5       linear                  10   \n",
       "1                   0.5       linear                  20   \n",
       "2                   0.5       linear                  30   \n",
       "3                   0.5       linear                  40   \n",
       "4                   0.5       linear                  50   \n",
       "5                   0.5       square                  10   \n",
       "6                   0.5       square                  20   \n",
       "7                   0.5       square                  30   \n",
       "8                   0.5       square                  40   \n",
       "9                   0.5       square                  50   \n",
       "10                  0.5  exponential                  10   \n",
       "11                  0.5  exponential                  20   \n",
       "12                  0.5  exponential                  30   \n",
       "13                  0.5  exponential                  40   \n",
       "14                  0.5  exponential                  50   \n",
       "15                  0.7       linear                  10   \n",
       "16                  0.7       linear                  20   \n",
       "17                  0.7       linear                  30   \n",
       "18                  0.7       linear                  40   \n",
       "19                  0.7       linear                  50   \n",
       "20                  0.7       square                  10   \n",
       "21                  0.7       square                  20   \n",
       "22                  0.7       square                  30   \n",
       "23                  0.7       square                  40   \n",
       "24                  0.7       square                  50   \n",
       "25                  0.7  exponential                  10   \n",
       "26                  0.7  exponential                  20   \n",
       "27                  0.7  exponential                  30   \n",
       "28                  0.7  exponential                  40   \n",
       "29                  0.7  exponential                  50   \n",
       "30                  1.0       linear                  10   \n",
       "31                  1.0       linear                  20   \n",
       "32                  1.0       linear                  30   \n",
       "33                  1.0       linear                  40   \n",
       "34                  1.0       linear                  50   \n",
       "35                  1.0       square                  10   \n",
       "36                  1.0       square                  20   \n",
       "37                  1.0       square                  30   \n",
       "38                  1.0       square                  40   \n",
       "39                  1.0       square                  50   \n",
       "40                  1.0  exponential                  10   \n",
       "41                  1.0  exponential                  20   \n",
       "42                  1.0  exponential                  30   \n",
       "43                  1.0  exponential                  40   \n",
       "44                  1.0  exponential                  50   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.5, 'loss': 'linear', 'n_es...          -4.753867   \n",
       "1   {'learning_rate': 0.5, 'loss': 'linear', 'n_es...          -4.786678   \n",
       "2   {'learning_rate': 0.5, 'loss': 'linear', 'n_es...          -4.941059   \n",
       "3   {'learning_rate': 0.5, 'loss': 'linear', 'n_es...          -4.611525   \n",
       "4   {'learning_rate': 0.5, 'loss': 'linear', 'n_es...          -4.702120   \n",
       "5   {'learning_rate': 0.5, 'loss': 'square', 'n_es...          -6.096165   \n",
       "6   {'learning_rate': 0.5, 'loss': 'square', 'n_es...          -4.458789   \n",
       "7   {'learning_rate': 0.5, 'loss': 'square', 'n_es...          -4.781372   \n",
       "8   {'learning_rate': 0.5, 'loss': 'square', 'n_es...          -4.319611   \n",
       "9   {'learning_rate': 0.5, 'loss': 'square', 'n_es...          -4.374747   \n",
       "10  {'learning_rate': 0.5, 'loss': 'exponential', ...          -4.821857   \n",
       "11  {'learning_rate': 0.5, 'loss': 'exponential', ...          -4.817566   \n",
       "12  {'learning_rate': 0.5, 'loss': 'exponential', ...          -5.200657   \n",
       "13  {'learning_rate': 0.5, 'loss': 'exponential', ...          -4.684127   \n",
       "14  {'learning_rate': 0.5, 'loss': 'exponential', ...          -4.717549   \n",
       "15  {'learning_rate': 0.7, 'loss': 'linear', 'n_es...          -3.813435   \n",
       "16  {'learning_rate': 0.7, 'loss': 'linear', 'n_es...          -5.386492   \n",
       "17  {'learning_rate': 0.7, 'loss': 'linear', 'n_es...          -4.374672   \n",
       "18  {'learning_rate': 0.7, 'loss': 'linear', 'n_es...          -4.928581   \n",
       "19  {'learning_rate': 0.7, 'loss': 'linear', 'n_es...          -4.689332   \n",
       "20  {'learning_rate': 0.7, 'loss': 'square', 'n_es...          -5.676341   \n",
       "21  {'learning_rate': 0.7, 'loss': 'square', 'n_es...          -4.596846   \n",
       "22  {'learning_rate': 0.7, 'loss': 'square', 'n_es...          -4.694396   \n",
       "23  {'learning_rate': 0.7, 'loss': 'square', 'n_es...          -3.926480   \n",
       "24  {'learning_rate': 0.7, 'loss': 'square', 'n_es...          -4.848206   \n",
       "25  {'learning_rate': 0.7, 'loss': 'exponential', ...          -5.023722   \n",
       "26  {'learning_rate': 0.7, 'loss': 'exponential', ...          -4.937362   \n",
       "27  {'learning_rate': 0.7, 'loss': 'exponential', ...          -4.880856   \n",
       "28  {'learning_rate': 0.7, 'loss': 'exponential', ...          -4.969742   \n",
       "29  {'learning_rate': 0.7, 'loss': 'exponential', ...          -5.192480   \n",
       "30  {'learning_rate': 1.0, 'loss': 'linear', 'n_es...          -4.249454   \n",
       "31  {'learning_rate': 1.0, 'loss': 'linear', 'n_es...          -5.289260   \n",
       "32  {'learning_rate': 1.0, 'loss': 'linear', 'n_es...          -4.263357   \n",
       "33  {'learning_rate': 1.0, 'loss': 'linear', 'n_es...          -4.426226   \n",
       "34  {'learning_rate': 1.0, 'loss': 'linear', 'n_es...          -4.707016   \n",
       "35  {'learning_rate': 1.0, 'loss': 'square', 'n_es...          -4.571060   \n",
       "36  {'learning_rate': 1.0, 'loss': 'square', 'n_es...          -4.033902   \n",
       "37  {'learning_rate': 1.0, 'loss': 'square', 'n_es...          -4.292934   \n",
       "38  {'learning_rate': 1.0, 'loss': 'square', 'n_es...          -4.094845   \n",
       "39  {'learning_rate': 1.0, 'loss': 'square', 'n_es...          -4.340896   \n",
       "40  {'learning_rate': 1.0, 'loss': 'exponential', ...          -4.452155   \n",
       "41  {'learning_rate': 1.0, 'loss': 'exponential', ...          -4.723088   \n",
       "42  {'learning_rate': 1.0, 'loss': 'exponential', ...          -5.029687   \n",
       "43  {'learning_rate': 1.0, 'loss': 'exponential', ...          -4.769882   \n",
       "44  {'learning_rate': 1.0, 'loss': 'exponential', ...          -4.722335   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           -6.196949         -12.063473          -3.882165   \n",
       "1           -5.304949         -11.623678          -4.186835   \n",
       "2           -4.702481          -8.565648          -2.868201   \n",
       "3           -5.618436          -7.106505          -3.516167   \n",
       "4           -5.504965          -7.592832          -3.206993   \n",
       "5           -6.829038         -15.042145          -3.106891   \n",
       "6           -4.928837          -8.482217          -3.048779   \n",
       "7           -5.717486          -8.084224          -4.956371   \n",
       "8           -4.720276          -7.591001          -3.906354   \n",
       "9           -4.854126          -6.727734          -3.484840   \n",
       "10          -5.579802         -13.417968          -4.524164   \n",
       "11          -6.368403          -8.066384          -4.344070   \n",
       "12          -4.766083          -8.737532          -4.416750   \n",
       "13          -5.002191          -8.666100          -3.161503   \n",
       "14          -4.021549          -8.901798          -3.066996   \n",
       "15          -5.434561         -12.827353          -2.454070   \n",
       "16          -4.689449          -9.396661          -4.508838   \n",
       "17          -4.588044          -9.341558          -4.732626   \n",
       "18          -4.582312          -6.295749          -3.436908   \n",
       "19          -4.986077          -7.227195          -4.015416   \n",
       "20          -6.879550         -10.896221          -3.839288   \n",
       "21          -6.261495          -8.334051          -4.412598   \n",
       "22          -4.931030          -6.689193          -3.636861   \n",
       "23          -5.718344          -9.217914          -3.062903   \n",
       "24          -4.226915         -10.355511          -4.498773   \n",
       "25          -5.425968          -8.976481          -2.738140   \n",
       "26          -4.085633         -13.154888          -3.726438   \n",
       "27          -6.070929         -11.614489          -3.699093   \n",
       "28          -4.175010          -8.024902          -3.640995   \n",
       "29          -4.407690          -6.913283          -4.034662   \n",
       "30          -3.906315         -13.376293          -3.419341   \n",
       "31          -5.758276          -9.882924          -2.999925   \n",
       "32          -5.108395         -11.240560          -3.957032   \n",
       "33          -4.701063          -6.440685          -3.473446   \n",
       "34          -4.616305          -5.974320          -3.245143   \n",
       "35          -4.583500          -7.184882          -2.877551   \n",
       "36          -4.999004          -7.521957          -3.357538   \n",
       "37          -4.640434          -8.069505          -3.028382   \n",
       "38          -4.920228          -8.392333          -3.215557   \n",
       "39          -4.522505          -5.713359          -2.438145   \n",
       "40          -6.544708          -5.841908          -2.453475   \n",
       "41          -4.461574          -9.746203          -3.434762   \n",
       "42          -7.461373          -8.004611          -3.508906   \n",
       "43          -4.526072          -7.635062          -3.021307   \n",
       "44          -4.132692          -7.618432          -2.835287   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           -2.615942        -5.902479        3.293838               42  \n",
       "1           -2.463238        -5.673076        3.125471               39  \n",
       "2           -2.424077        -4.700293        2.169639               20  \n",
       "3           -2.301671        -4.630861        1.659648               15  \n",
       "4           -3.103189        -4.822020        1.656555               22  \n",
       "5           -2.406029        -6.696054        4.501582               45  \n",
       "6           -2.533450        -4.690415        2.089772               19  \n",
       "7           -2.080622        -5.124015        1.924723               26  \n",
       "8           -2.536390        -4.614726        1.659983               14  \n",
       "9           -2.772161        -4.442722        1.349330                8  \n",
       "10          -2.948474        -6.258453        3.680944               44  \n",
       "11          -2.772732        -5.273831        1.806907               31  \n",
       "12          -2.716440        -5.167492        1.973762               28  \n",
       "13          -2.257398        -4.754264        2.197274               21  \n",
       "14          -2.449611        -4.631500        2.272584               16  \n",
       "15          -3.041207        -5.514125        3.791075               37  \n",
       "16          -2.450665        -5.286421        2.276252               32  \n",
       "17          -2.926117        -5.192604        2.172412               29  \n",
       "18          -2.640958        -4.376902        1.259016                5  \n",
       "19          -3.197981        -4.823200        1.350370               23  \n",
       "20          -3.465600        -6.151400        2.676886               43  \n",
       "21          -3.277911        -5.376580        1.759055               36  \n",
       "22          -1.877201        -4.365736        1.584304                3  \n",
       "23          -2.631015        -4.911331        2.399349               24  \n",
       "24          -2.749405        -5.335762        2.609786               33  \n",
       "25          -3.462194        -5.125301        2.163181               27  \n",
       "26          -2.926052        -5.766075        3.750495               40  \n",
       "27          -2.625074        -5.778088        3.137453               41  \n",
       "28          -2.502172        -4.662564        1.862701               17  \n",
       "29          -2.447378        -4.599098        1.462373               12  \n",
       "30          -3.167031        -5.623687        3.894485               38  \n",
       "31          -2.869267        -5.359931        2.545356               34  \n",
       "32          -2.248006        -5.363470        3.082197               35  \n",
       "33          -2.982089        -4.404702        1.193699                6  \n",
       "34          -2.410603        -4.190678        1.240310                2  \n",
       "35          -3.074147        -4.458228        1.541252                9  \n",
       "36          -2.211811        -4.424842        1.795063                7  \n",
       "37          -2.721011        -4.550453        1.903770               11  \n",
       "38          -2.774845        -4.679562        1.997786               18  \n",
       "39          -3.040680        -4.011117        1.156191                1  \n",
       "40          -2.549313        -4.368312        1.666768                4  \n",
       "41          -2.670276        -5.007181        2.480740               25  \n",
       "42          -2.235920        -5.248099        2.220030               30  \n",
       "43          -3.103187        -4.611102        1.672007               13  \n",
       "44          -2.987758        -4.459301        1.729672               10  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame.from_dict(re)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e6c6341-9731-4a2d-bd5e-86c9134bc347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter R&D spend value: 464574\n",
      "Enter Administration spend: 2345\n",
      "Enter Marketing spend: 3255\n",
      "Enter 0 or 1 for State_florida: 0\n",
      "Enter 0 or 1 for State_newYork: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future_Prediction=[159199.855]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hxtreme\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rd_spend = float(input(\"Enter R&D spend value:\"))\n",
    "admin_value = float(input(\"Enter Administration spend:\"))\n",
    "marketing_spend = float(input(\"Enter Marketing spend:\"))\n",
    "state_input1 = int(input(\"Enter 0 or 1 for State_florida:\"))\n",
    "state_input2 = int(input(\"Enter 0 or 1 for State_newYork:\"))\n",
    "Future_Prediction=grid.predict([[rd_spend,admin_value,marketing_spend,state_input1,state_input2]])\n",
    "print(\"Future_Prediction={}\".format(Future_Prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852e683e-57d5-4c4c-89fa-323ff5b5c46b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
